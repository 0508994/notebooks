{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(state='KS', account_length=128.0, area_code=' 415', phone_number=' 382-4657', international_plan=' no', voice_mail_plan=' yes', number_vmail_messages=25.0, total_day_minutes=265.1, total_day_calls=110.0, total_day_charge=45.07, total_eve_minutes=197.4, total_eve_calls=99.0, total_eve_charge=16.78, total_night_minutes=244.7, total_night_calls=91.0, total_night_charge=11.01, total_intl_minutes=10.0, total_intl_calls=3.0, total_intl_charge=2.7, number_customer_service_calls=1.0, churned=' False.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "schema = StructType([StructField(\"state\", StringType(), True),\n",
    "                     StructField(\"account_length\", DoubleType(), True),\n",
    "                     StructField(\"area_code\", StringType(), True),\n",
    "                     StructField(\"phone_number\", StringType(), True),\n",
    "                     StructField(\"international_plan\", StringType(), True),\n",
    "                     StructField(\"voice_mail_plan\", StringType(), True),\n",
    "                     StructField(\"number_vmail_messages\", DoubleType(), True),\n",
    "                     StructField(\"total_day_minutes\", DoubleType(), True),\n",
    "                     StructField(\"total_day_calls\", DoubleType(), True),\n",
    "                     StructField(\"total_day_charge\", DoubleType(), True),\n",
    "                     StructField(\"total_eve_minutes\", DoubleType(), True),\n",
    "                     StructField(\"total_eve_calls\", DoubleType(), True),\n",
    "                     StructField(\"total_eve_charge\", DoubleType(), True),\n",
    "                     StructField(\"total_night_minutes\", DoubleType(), True),\n",
    "                     StructField(\"total_night_calls\", DoubleType(), True),\n",
    "                     StructField(\"total_night_charge\", DoubleType(), True),\n",
    "                     StructField(\"total_intl_minutes\", DoubleType(), True),\n",
    "                     StructField(\"total_intl_calls\", DoubleType(), True),\n",
    "                     StructField(\"total_intl_charge\", DoubleType(), True),\n",
    "                     StructField(\"number_customer_service_calls\", DoubleType(), True),\n",
    "                     StructField(\"churned\", StringType(), True)])\n",
    "\n",
    "df = sqlContext.read.format('com.databricks.spark.csv').load('churn.all', schema = schema)\n",
    "df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assemble feature vectors\n",
    "\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols = [\n",
    "        'number_customer_service_calls', \\\n",
    "        'total_night_minutes', \\\n",
    "        'total_day_minutes', \\\n",
    "        'total_eve_minutes', \\\n",
    "        'account_length'],\n",
    "    outputCol = 'features')\n",
    "\n",
    "# Transform labels\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "label_indexer = StringIndexer(inputCol = 'churned', outputCol = 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(labelCol = 'label', featuresCol = 'features')\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, label_indexer, classifier])\n",
    "\n",
    "(train, test) = df.randomSplit([0.8, 0.2])\n",
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8644895984518621"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "predictions = model.transform(train)\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "evaluator.evaluate(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
